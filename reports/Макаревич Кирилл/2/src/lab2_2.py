import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

print("=" * 60)
print("–ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ì–†–ò–ë–û–í –° –ü–û–ú–û–©–¨–Æ PCA")
print("=" * 60)

print("–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
np.random.seed(42)
n_samples = 2000

columns = [
    'class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',
    'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',
    'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',
    'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color',
    'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'
]

data = {
    'class': np.random.choice(['edible', 'poisonous'], n_samples, p=[0.6, 0.4]),
}

for i, col in enumerate(columns[1:]):
    if i % 3 == 0:
        data[col] = np.where(data['class'] == 'edible',
                            np.random.choice(['a', 'b', 'c'], n_samples, p=[0.7, 0.2, 0.1]),
                            np.random.choice(['a', 'b', 'c'], n_samples, p=[0.1, 0.2, 0.7]))
    elif i % 3 == 1:
        data[col] = np.where(data['class'] == 'edible',
                            np.random.choice(['x', 'y', 'z'], n_samples, p=[0.6, 0.3, 0.1]),
                            np.random.choice(['x', 'y', 'z'], n_samples, p=[0.2, 0.4, 0.4]))
    else:
        data[col] = np.random.choice(['m', 'n', 'o', 'p'], n_samples)

data = pd.DataFrame(data)
print("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã!")

print(f"\n–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {data.shape}")
print(f"–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö:")
print(data.head())

print("\n–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
print(data.isnull().sum())

print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
class_counts = data['class'].value_counts()
print(class_counts)
print(f"–°—ä–µ–¥–æ–±–Ω—ã–µ: {class_counts['edible']} ({class_counts['edible']/len(data)*100:.1f}%)")
print(f"–Ø–¥–æ–≤–∏—Ç—ã–µ: {class_counts['poisonous']} ({class_counts['poisonous']/len(data)*100:.1f}%)")

X = data.drop('class', axis=1)
y = data['class']

print(f"\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(X.columns)}")
print("–ü—Ä–∏–∑–Ω–∞–∫–∏:", X.columns.tolist())

label_encoders = {}
X_encoded = X.copy()

print("\n–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
for column in X.columns:
    le = LabelEncoder()
    X_encoded[column] = le.fit_transform(X[column].astype(str))
    label_encoders[column] = le
    print(f"  {column}: {len(le.classes_)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_encoded)

print(f"\n–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {X_scaled.shape}")

print("\n" + "="*60)
print("–í–´–ü–û–õ–ù–ï–ù–ò–ï PCA –ê–ù–ê–õ–ò–ó–ê")
print("="*60)

print("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è PCA —Å 2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏...")
pca_2d = PCA(n_components=2, random_state=42)
X_pca_2d = pca_2d.fit_transform(X_scaled)
print("PCA 2D –∑–∞–≤–µ—Ä—à–µ–Ω!")

print("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è PCA —Å 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏...")
pca_3d = PCA(n_components=3, random_state=42)
X_pca_3d = pca_3d.fit_transform(X_scaled)
print("PCA 3D –∑–∞–≤–µ—Ä—à–µ–Ω!")

print("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π PCA –∞–Ω–∞–ª–∏–∑...")
pca_full = PCA()
X_pca_full = pca_full.fit_transform(X_scaled)
print("–ü–æ–ª–Ω—ã–π PCA –∑–∞–≤–µ—Ä—à–µ–Ω!")

print(f"\n–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å PCA 2D: {X_pca_2d.shape}")
print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å PCA 3D: {X_pca_3d.shape}")

explained_variance_2d = pca_2d.explained_variance_ratio_
explained_variance_3d = pca_3d.explained_variance_ratio_
explained_variance_full = pca_full.explained_variance_ratio_

print(f"\n–û–ë–™–Ø–°–ù–ï–ù–ù–ê–Ø –î–ò–°–ü–ï–†–°–ò–Ø:")
print(f"PCA 2D - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1: {explained_variance_2d[0]:.3f} ({explained_variance_2d[0]*100:.1f}%)")
print(f"PCA 2D - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2: {explained_variance_2d[1]:.3f} ({explained_variance_2d[1]*100:.1f}%)")
print(f"PCA 2D - –°—É–º–º–∞—Ä–Ω–æ: {explained_variance_2d.sum():.3f} ({explained_variance_2d.sum()*100:.1f}%)")

print(f"\nPCA 3D - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1: {explained_variance_3d[0]:.3f} ({explained_variance_3d[0]*100:.1f}%)")
print(f"PCA 3D - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2: {explained_variance_3d[1]:.3f} ({explained_variance_3d[1]*100:.1f}%)")
print(f"PCA 3D - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 3: {explained_variance_3d[2]:.3f} ({explained_variance_3d[2]*100:.1f}%)")
print(f"PCA 3D - –°—É–º–º–∞—Ä–Ω–æ: {explained_variance_3d.sum():.3f} ({explained_variance_3d.sum()*100:.1f}%)")

fig = plt.figure(figsize=(20, 15))

colors = {'edible': 'green', 'poisonous': 'red'}
class_names = {'edible': '–°—ä–µ–¥–æ–±–Ω—ã–µ', 'poisonous': '–Ø–¥–æ–≤–∏—Ç—ã–µ'}

ax1 = fig.add_subplot(2, 3, 1)
for class_label in colors.keys():
    mask = y == class_label
    ax1.scatter(X_pca_2d[mask, 0], X_pca_2d[mask, 1],
               c=colors[class_label], label=class_names[class_label],
               alpha=0.7, s=50, edgecolors='w', linewidth=0.5)
ax1.set_title(f'PCA: 2D –ü—Ä–æ–µ–∫—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n(–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {explained_variance_2d.sum()*100:.1f}%)',
              fontsize=14, fontweight='bold')
ax1.set_xlabel(f'PC1 ({explained_variance_2d[0]*100:.1f}%)')
ax1.set_ylabel(f'PC2 ({explained_variance_2d[1]*100:.1f}%)')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2 = fig.add_subplot(2, 3, 2, projection='3d')
for class_label in colors.keys():
    mask = y == class_label
    ax2.scatter(X_pca_3d[mask, 0], X_pca_3d[mask, 1], X_pca_3d[mask, 2],
               c=colors[class_label], label=class_names[class_label],
               alpha=0.7, s=50, edgecolors='w', linewidth=0.5)
ax2.set_title(f'PCA: 3D –ü—Ä–æ–µ–∫—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n(–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {explained_variance_3d.sum()*100:.1f}%)',
              fontsize=14, fontweight='bold')
ax2.set_xlabel(f'PC1 ({explained_variance_3d[0]*100:.1f}%)')
ax2.set_ylabel(f'PC2 ({explained_variance_3d[1]*100:.1f}%)')
ax2.set_zlabel(f'PC3 ({explained_variance_3d[2]*100:.1f}%)')
ax2.legend()

ax3 = fig.add_subplot(2, 3, 3)
cumulative_variance = np.cumsum(explained_variance_full)
components = range(1, len(explained_variance_full) + 1)

ax3.bar(components, explained_variance_full, alpha=0.6, color='skyblue', label='–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è')
ax3.plot(components, cumulative_variance, 'ro-', linewidth=2, markersize=6, label='–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è')

ax3.set_title('–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç', fontsize=14, fontweight='bold')
ax3.set_xlabel('–ù–æ–º–µ—Ä –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã')
ax3.set_ylabel('–î–æ–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏')
ax3.legend()
ax3.grid(True, alpha=0.3)

for i, (variance, cum_variance) in enumerate(zip(explained_variance_full[:10], cumulative_variance[:10])):
    if i < 5 or cum_variance > 0.8:
        ax3.annotate(f'{cum_variance:.1%}', (components[i], cum_variance),
                    textcoords="offset points", xytext=(0,10), ha='center', fontsize=8)

ax4 = fig.add_subplot(2, 3, 4)
loadings = pca_2d.components_.T
feature_names = X.columns

top_features_idx = np.argsort(np.abs(loadings[:, 0]))[-10:]
top_features = feature_names[top_features_idx]
top_loadings = loadings[top_features_idx]

im = ax4.imshow(top_loadings, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)
ax4.set_xticks([0, 1])
ax4.set_xticklabels(['PC1', 'PC2'])
ax4.set_yticks(range(len(top_features)))
ax4.set_yticklabels(top_features)
ax4.set_title('–í–∫–ª–∞–¥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n(–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è PC1)', fontsize=14, fontweight='bold')

for i in range(len(top_features)):
    for j in range(2):
        text = ax4.text(j, i, f'{top_loadings[i, j]:.2f}',
                       ha="center", va="center", color="black", fontweight='bold')

plt.colorbar(im, ax=ax4, label='–í–∫–ª–∞–¥ –ø—Ä–∏–∑–Ω–∞–∫–∞')

ax5 = fig.add_subplot(2, 3, 5)
boxplot_data = []
labels = []

for i in range(2):
    boxplot_data.extend([X_pca_2d[y == 'edible', i], X_pca_2d[y == 'poisonous', i]])
    labels.extend([f'PC{i+1}\n–°—ä–µ–¥–æ–±–Ω—ã–µ', f'PC{i+1}\n–Ø–¥–æ–≤–∏—Ç—ã–µ'])

box = ax5.boxplot(boxplot_data, labels=labels, patch_artist=True)
colors_box = ['lightgreen', 'lightcoral'] * 2
for patch, color in zip(box['boxes'], colors_box):
    patch.set_facecolor(color)

ax5.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–ª–∞–≤–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º', fontsize=14, fontweight='bold')
ax5.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã')
plt.xticks(rotation=45)

ax6 = fig.add_subplot(2, 3, 6)

def calculate_separation_quality(projection, y):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤"""
    edible_data = projection[y == 'edible']
    poisonous_data = projection[y == 'poisonous']

    center_distance = np.linalg.norm(edible_data.mean(axis=0) - poisonous_data.mean(axis=0))

    within_class_var = (edible_data.var(axis=0).mean() + poisonous_data.var(axis=0).mean()) / 2

    separation_score = center_distance / (within_class_var + 1e-8)

    return separation_score

components_to_test = [2, 3, 5, 10]
separability_scores = []

for n_comp in components_to_test:
    pca_temp = PCA(n_components=n_comp)
    X_temp = pca_temp.fit_transform(X_scaled)
    score = calculate_separation_quality(X_temp, y)
    separability_scores.append(score)

bars = ax6.bar([f'PCA-{n}' for n in components_to_test], separability_scores,
               color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])
ax6.set_title('–†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏ —Ä–∞–∑–Ω–æ–º\n–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç', fontsize=14, fontweight='bold')
ax6.set_ylabel('–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç–∏\n(–±–æ–ª—å—à–µ = –ª—É—á—à–µ)')
ax6.grid(True, alpha=0.3, axis='y')

for bar, score in zip(bars, separability_scores):
    height = bar.get_height()
    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.1,
             f'{score:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=12)

plt.tight_layout()
plt.show()

print("\n" + "="*60)
print("–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó PCA –ö–û–ú–ü–û–ù–ï–ù–¢")
print("="*60)

print("\nPCA 2D –ö–û–ú–ü–û–ù–ï–ù–¢–´:")
for j in range(2):
    edible_activations = X_pca_2d[y == 'edible', j]
    poisonous_activations = X_pca_2d[y == 'poisonous', j]

    t_stat, p_value = stats.ttest_ind(edible_activations, poisonous_activations)

    significance = ''
    if p_value < 0.001:
        significance = '***'
    elif p_value < 0.01:
        significance = '**'
    elif p_value < 0.05:
        significance = '*'

    print(f"  PC{j+1}:")
    print(f"    –°—ä–µ–¥–æ–±–Ω—ã–µ: Œº={edible_activations.mean():.3f}, œÉ={edible_activations.std():.3f}")
    print(f"    –Ø–¥–æ–≤–∏—Ç—ã–µ:  Œº={poisonous_activations.mean():.3f}, œÉ={poisonous_activations.std():.3f}")
    print(f"    t-—Ç–µ—Å—Ç: p-value = {p_value:.6f} {significance}")

print("\n" + "="*60)
print("–ê–ù–ê–õ–ò–ó –ì–õ–ê–í–ù–´–• –ö–û–ú–ü–û–ù–ï–ù–¢")
print("="*60)

print("\n–¢–û–ü-5 –ü–†–ò–ó–ù–ê–ö–û–í –ü–û –í–ö–õ–ê–î–£ –í –ö–û–ú–ü–û–ù–ï–ù–¢–´:")

for i in range(3):
    print(f"\nPC{i+1} ({explained_variance_full[i]*100:.1f}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏):")
    loadings = pca_full.components_[i]
    top_indices = np.argsort(np.abs(loadings))[-5:][::-1]

    for idx in top_indices:
        feature_name = feature_names[idx]
        loading_value = loadings[idx]
        print(f"  {feature_name}: {loading_value:.3f}")

print("\n" + "="*60)
print("–ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó –ò –í–´–í–û–î–´ PCA")
print("="*60)

print(f"\nüìä –û–°–ù–û–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
print(f"   ‚Ä¢ –ü–µ—Ä–≤—ã–µ 2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ–±—ä—è—Å–Ω—è—é—Ç {explained_variance_2d.sum()*100:.1f}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
print(f"   ‚Ä¢ –ü–µ—Ä–≤—ã–µ 3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ–±—ä—è—Å–Ω—è—é—Ç {explained_variance_3d.sum()*100:.1f}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
print(f"   ‚Ä¢ –î–ª—è 80% –¥–∏—Å–ø–µ—Ä—Å–∏–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è {np.argmax(cumulative_variance >= 0.8) + 1} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç")

print(f"\nüîç –ö–ê–ß–ï–°–¢–í–û –†–ê–ó–î–ï–õ–ï–ù–ò–Ø –ö–õ–ê–°–°–û–í:")
best_n_components = components_to_test[np.argmax(separability_scores)]
print(f"   ‚Ä¢ –õ—É—á—à–µ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏ {best_n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö")
print(f"   ‚Ä¢ –ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç–∏: {max(separability_scores):.3f}")

print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
print(f"   ‚Ä¢ –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 2-3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã")
print(f"   ‚Ä¢ –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {np.argmax(cumulative_variance >= 0.8) + 1} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è 80% –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
print(f"   ‚Ä¢ –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å {best_n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç")

print(f"\nüéØ –ü–†–ê–ö–¢–ò–ß–ï–°–ö–û–ï –ü–†–ò–ú–ï–ù–ï–ù–ò–ï:")
print("   ‚Ä¢ –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö")
print("   ‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
print("   ‚Ä¢ –í—ã—è–≤–ª–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print("   ‚Ä¢ –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

print("\n" + "="*60)
print("PCA –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù! üéâ")
print("="*60)

print(f"\n–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
print(f"   ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(data)}")
print(f"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {X_scaled.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print(f"   ‚Ä¢ –°—ä–µ–¥–æ–±–Ω—ã–µ –≥—Ä–∏–±—ã: {(y == 'edible').sum()} ({((y == 'edible').sum()/len(y)*100):.1f}%)")
print(f"   ‚Ä¢ –Ø–¥–æ–≤–∏—Ç—ã–µ –≥—Ä–∏–±—ã: {(y == 'poisonous').sum()} ({((y == 'poisonous').sum()/len(y)*100):.1f}%)")
